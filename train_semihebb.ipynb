{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sys.path.append('../')\n",
    "from data.load_data import *\n",
    "from models.neural_networks import *\n",
    "from train.train_cnn import *\n",
    "from train.train_fcn import *\n",
    "from train.train_semihebb import *\n",
    "from evaluation.test import *\n",
    "from utils.others import *\n",
    "from utils.plot import *\n",
    "from utils.save_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Hebb rule\n",
    "\n",
    "note that hebbian weights goes to infinity, values will be NaN after they go out of the range, so tSNE plot cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 2.320737838745117, Accuracy: 11.35%\n",
      "Epoch: 0, Step: 50, Loss: 1.9118914604187012, Accuracy: 31.28%\n",
      "Epoch: 0, Step: 100, Loss: 1.8061134815216064, Accuracy: 36.31%\n",
      "Epoch: 0, Step: 150, Loss: 1.562354564666748, Accuracy: 49.0%\n",
      "Epoch: 0, Step: 200, Loss: 1.3082427978515625, Accuracy: 59.44%\n",
      "Epoch: 0, Step: 250, Loss: 1.6132625341415405, Accuracy: 67.73%\n",
      "Epoch: 0, Step: 300, Loss: 1.298007845878601, Accuracy: 69.16%\n",
      "Epoch: 0, Step: 350, Loss: 1.1100846529006958, Accuracy: 66.96%\n",
      "Epoch: 0, Step: 400, Loss: 1.1102190017700195, Accuracy: 75.45%\n",
      "Epoch: 0, Step: 450, Loss: 1.1770377159118652, Accuracy: 65.27%\n",
      "Epoch: 0, Step: 500, Loss: 0.8903278112411499, Accuracy: 75.43%\n",
      "Epoch: 0, Step: 550, Loss: 0.7944438457489014, Accuracy: 65.44%\n",
      "Epoch: 0, Step: 600, Loss: 0.9019562005996704, Accuracy: 83.08%\n",
      "Epoch: 0, Step: 650, Loss: 0.6638520956039429, Accuracy: 81.49%\n",
      "Epoch: 0, Step: 700, Loss: 0.7416394948959351, Accuracy: 71.66%\n",
      "Epoch: 0, Step: 750, Loss: 0.8208505511283875, Accuracy: 80.58%\n",
      "Epoch: 0, Step: 800, Loss: 0.988426685333252, Accuracy: 74.81%\n",
      "Epoch: 0, Step: 850, Loss: 0.7310705780982971, Accuracy: 74.24%\n",
      "Epoch: 0, Step: 900, Loss: 0.653241753578186, Accuracy: 75.78%\n",
      "Epoch: 0, Step: 950, Loss: 0.6130303740501404, Accuracy: 78.55%\n",
      "Epoch: 0, Step: 1000, Loss: 0.6668863892555237, Accuracy: 82.07%\n",
      "Epoch: 0, Step: 1050, Loss: 0.6770164966583252, Accuracy: 86.84%\n",
      "Epoch: 0, Step: 1100, Loss: 0.31176114082336426, Accuracy: 85.11%\n",
      "Epoch: 0, Step: 1150, Loss: 0.4025838077068329, Accuracy: 82.23%\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001             \n",
    "TSNE = True\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "#load CIFAR-10 dataset\n",
    "\n",
    "\n",
    "# Plot one example\n",
    "plot_example(train_loader)\n",
    "\n",
    "TSNE = False\n",
    "\n",
    "# create model instance\n",
    "\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='hebb',p=None)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SemiHebbNet on the MNIST test images: 78.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Oja's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "Epoch: 0, Step: 0, Loss: 2.314085006713867, Accuracy: 9.43%\n",
      "Epoch: 0, Step: 50, Loss: 2.2312917709350586, Accuracy: 29.21%\n",
      "Epoch: 0, Step: 100, Loss: 2.1097075939178467, Accuracy: 54.85%\n",
      "Epoch: 0, Step: 150, Loss: 1.9586182832717896, Accuracy: 61.1%\n",
      "Epoch: 0, Step: 200, Loss: 1.864109992980957, Accuracy: 63.63%\n",
      "Epoch: 0, Step: 250, Loss: 1.6955351829528809, Accuracy: 70.86%\n",
      "Epoch: 0, Step: 300, Loss: 1.6053637266159058, Accuracy: 68.47%\n",
      "Epoch: 0, Step: 350, Loss: 1.5876286029815674, Accuracy: 70.69%\n",
      "Epoch: 0, Step: 400, Loss: 1.4423426389694214, Accuracy: 77.01%\n",
      "Epoch: 0, Step: 450, Loss: 1.4346058368682861, Accuracy: 76.99%\n",
      "Epoch: 0, Step: 500, Loss: 1.3831783533096313, Accuracy: 79.45%\n",
      "Epoch: 0, Step: 550, Loss: 1.293118953704834, Accuracy: 80.01%\n",
      "Epoch: 0, Step: 600, Loss: 1.2180126905441284, Accuracy: 81.03%\n",
      "Epoch: 0, Step: 650, Loss: 1.204261302947998, Accuracy: 81.51%\n",
      "Epoch: 0, Step: 700, Loss: 1.1364930868148804, Accuracy: 82.05%\n",
      "Epoch: 0, Step: 750, Loss: 1.0642225742340088, Accuracy: 81.18%\n",
      "Epoch: 0, Step: 800, Loss: 1.2223716974258423, Accuracy: 83.3%\n",
      "Epoch: 0, Step: 850, Loss: 1.109928011894226, Accuracy: 82.82%\n",
      "Epoch: 0, Step: 900, Loss: 1.058547854423523, Accuracy: 83.69%\n",
      "Epoch: 0, Step: 950, Loss: 0.9861540794372559, Accuracy: 84.22%\n",
      "Epoch: 0, Step: 1000, Loss: 0.8617392778396606, Accuracy: 82.4%\n",
      "Epoch: 0, Step: 1050, Loss: 0.8583933115005493, Accuracy: 84.61%\n",
      "Epoch: 0, Step: 1100, Loss: 0.8422145247459412, Accuracy: 84.04%\n",
      "Epoch: 0, Step: 1150, Loss: 0.9008110165596008, Accuracy: 84.83%\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.0001             \n",
    "TSNE = False\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "\n",
    "# create model instance\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='oja',p=None)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                  \n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SemiHebbNet on the MNIST test images: 84.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Gupta's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "Epoch: 0, Step: 0, Loss: 2.314798355102539, Accuracy: 17.83%\n",
      "Epoch: 0, Step: 50, Loss: 1.0973141193389893, Accuracy: 78.38%\n",
      "Epoch: 0, Step: 100, Loss: 0.7684252262115479, Accuracy: 84.81%\n",
      "Epoch: 0, Step: 150, Loss: 0.666536808013916, Accuracy: 86.29%\n",
      "Epoch: 0, Step: 200, Loss: 0.5300126671791077, Accuracy: 87.66%\n",
      "Epoch: 0, Step: 250, Loss: 0.7640625238418579, Accuracy: 87.74%\n",
      "Epoch: 0, Step: 300, Loss: 0.4310745894908905, Accuracy: 89.13%\n",
      "Epoch: 0, Step: 350, Loss: 0.3499631881713867, Accuracy: 88.95%\n",
      "Epoch: 0, Step: 400, Loss: 0.5048956274986267, Accuracy: 89.05%\n",
      "Epoch: 0, Step: 450, Loss: 0.5177027583122253, Accuracy: 89.68%\n",
      "Epoch: 0, Step: 500, Loss: 0.5507404208183289, Accuracy: 89.77%\n",
      "Epoch: 0, Step: 550, Loss: 0.4987338185310364, Accuracy: 90.28%\n",
      "Epoch: 0, Step: 600, Loss: 0.3004152774810791, Accuracy: 90.52%\n",
      "Epoch: 0, Step: 650, Loss: 0.40719497203826904, Accuracy: 90.44%\n",
      "Epoch: 0, Step: 700, Loss: 0.321654349565506, Accuracy: 90.73%\n",
      "Epoch: 0, Step: 750, Loss: 0.36673033237457275, Accuracy: 90.79%\n",
      "Epoch: 0, Step: 800, Loss: 0.22224406898021698, Accuracy: 91.23%\n",
      "Epoch: 0, Step: 850, Loss: 0.18779020011425018, Accuracy: 91.41%\n",
      "Epoch: 0, Step: 900, Loss: 0.47777724266052246, Accuracy: 91.0%\n",
      "Epoch: 0, Step: 950, Loss: 0.3859228193759918, Accuracy: 91.49%\n",
      "Epoch: 0, Step: 1000, Loss: 0.2475321739912033, Accuracy: 91.9%\n",
      "Epoch: 0, Step: 1050, Loss: 0.4534309506416321, Accuracy: 91.79%\n",
      "Epoch: 0, Step: 1100, Loss: 0.27849292755126953, Accuracy: 91.82%\n",
      "Epoch: 0, Step: 1150, Loss: 0.27457377314567566, Accuracy: 92.07%\n",
      "Epoch: 1, Step: 0, Loss: 0.2672699987888336, Accuracy: 89.34%\n",
      "Epoch: 1, Step: 50, Loss: 0.664141833782196, Accuracy: 91.24%\n",
      "Epoch: 1, Step: 100, Loss: 0.576120138168335, Accuracy: 91.0%\n",
      "Epoch: 1, Step: 150, Loss: 0.57699054479599, Accuracy: 91.26%\n",
      "Epoch: 1, Step: 200, Loss: 0.408092737197876, Accuracy: 90.98%\n",
      "Epoch: 1, Step: 250, Loss: 0.5367986559867859, Accuracy: 91.08%\n",
      "Epoch: 1, Step: 300, Loss: 0.440367728471756, Accuracy: 90.99%\n",
      "Epoch: 1, Step: 350, Loss: 0.3805910050868988, Accuracy: 91.21%\n",
      "Epoch: 1, Step: 400, Loss: 0.24974177777767181, Accuracy: 91.23%\n",
      "Epoch: 1, Step: 450, Loss: 0.41143229603767395, Accuracy: 91.33%\n",
      "Epoch: 1, Step: 500, Loss: 0.38252514600753784, Accuracy: 91.42%\n",
      "Epoch: 1, Step: 550, Loss: 0.41782146692276, Accuracy: 91.7%\n",
      "Epoch: 1, Step: 600, Loss: 0.28124362230300903, Accuracy: 91.48%\n",
      "Epoch: 1, Step: 650, Loss: 0.365198016166687, Accuracy: 91.58%\n",
      "Epoch: 1, Step: 700, Loss: 0.4440031051635742, Accuracy: 91.58%\n",
      "Epoch: 1, Step: 750, Loss: 0.241124227643013, Accuracy: 91.83%\n",
      "Epoch: 1, Step: 800, Loss: 0.3752335011959076, Accuracy: 91.69%\n",
      "Epoch: 1, Step: 850, Loss: 0.29991233348846436, Accuracy: 91.84%\n",
      "Epoch: 1, Step: 900, Loss: 0.5073774456977844, Accuracy: 91.91%\n",
      "Epoch: 1, Step: 950, Loss: 0.428379088640213, Accuracy: 92.12%\n",
      "Epoch: 1, Step: 1000, Loss: 0.3857719898223877, Accuracy: 92.01%\n",
      "Epoch: 1, Step: 1050, Loss: 0.28512802720069885, Accuracy: 91.98%\n",
      "Epoch: 1, Step: 1100, Loss: 0.36647894978523254, Accuracy: 92.12%\n",
      "Epoch: 1, Step: 1150, Loss: 0.29032373428344727, Accuracy: 92.15%\n",
      "Epoch: 2, Step: 0, Loss: 0.38378679752349854, Accuracy: 89.69%\n",
      "Epoch: 2, Step: 50, Loss: 0.42415520548820496, Accuracy: 92.22%\n",
      "Epoch: 2, Step: 100, Loss: 0.2942567467689514, Accuracy: 92.16%\n",
      "Epoch: 2, Step: 150, Loss: 0.2804732918739319, Accuracy: 92.12%\n",
      "Epoch: 2, Step: 200, Loss: 0.4217129051685333, Accuracy: 92.24%\n",
      "Epoch: 2, Step: 250, Loss: 0.362092524766922, Accuracy: 92.28%\n",
      "Epoch: 2, Step: 300, Loss: 0.5047067999839783, Accuracy: 92.31%\n",
      "Epoch: 2, Step: 350, Loss: 0.29681721329689026, Accuracy: 92.37%\n",
      "Epoch: 2, Step: 400, Loss: 0.27860552072525024, Accuracy: 92.33%\n",
      "Epoch: 2, Step: 450, Loss: 0.4690243899822235, Accuracy: 92.36%\n",
      "Epoch: 2, Step: 500, Loss: 0.25476405024528503, Accuracy: 92.37%\n",
      "Epoch: 2, Step: 550, Loss: 0.32273975014686584, Accuracy: 92.37%\n",
      "Epoch: 2, Step: 600, Loss: 0.20881527662277222, Accuracy: 92.54%\n",
      "Epoch: 2, Step: 650, Loss: 0.25424784421920776, Accuracy: 92.31%\n",
      "Epoch: 2, Step: 700, Loss: 0.29908376932144165, Accuracy: 92.41%\n",
      "Epoch: 2, Step: 750, Loss: 0.3989999294281006, Accuracy: 92.5%\n",
      "Epoch: 2, Step: 800, Loss: 0.3174281716346741, Accuracy: 92.53%\n",
      "Epoch: 2, Step: 850, Loss: 0.381730854511261, Accuracy: 92.52%\n",
      "Epoch: 2, Step: 900, Loss: 0.15612491965293884, Accuracy: 92.57%\n",
      "Epoch: 2, Step: 950, Loss: 0.46168869733810425, Accuracy: 92.75%\n",
      "Epoch: 2, Step: 1000, Loss: 0.23358102142810822, Accuracy: 92.66%\n",
      "Epoch: 2, Step: 1050, Loss: 0.19805803894996643, Accuracy: 92.68%\n",
      "Epoch: 2, Step: 1100, Loss: 0.31771180033683777, Accuracy: 92.83%\n",
      "Epoch: 2, Step: 1150, Loss: 0.1898576319217682, Accuracy: 92.68%\n",
      "Epoch: 3, Step: 0, Loss: 0.27035051584243774, Accuracy: 90.85%\n",
      "Epoch: 3, Step: 50, Loss: 0.5570077896118164, Accuracy: 92.08%\n",
      "Epoch: 3, Step: 100, Loss: 0.4130389392375946, Accuracy: 92.2%\n",
      "Epoch: 3, Step: 150, Loss: 0.42951512336730957, Accuracy: 92.19%\n",
      "Epoch: 3, Step: 200, Loss: 0.3905194103717804, Accuracy: 92.17%\n",
      "Epoch: 3, Step: 250, Loss: 0.2912169396877289, Accuracy: 92.28%\n",
      "Epoch: 3, Step: 300, Loss: 0.37464603781700134, Accuracy: 92.2%\n",
      "Epoch: 3, Step: 350, Loss: 0.29895681142807007, Accuracy: 92.26%\n",
      "Epoch: 3, Step: 400, Loss: 0.3338814973831177, Accuracy: 92.32%\n",
      "Epoch: 3, Step: 450, Loss: 0.2687079906463623, Accuracy: 92.33%\n",
      "Epoch: 3, Step: 500, Loss: 0.2929385006427765, Accuracy: 92.41%\n",
      "Epoch: 3, Step: 550, Loss: 0.174132838845253, Accuracy: 92.41%\n",
      "Epoch: 3, Step: 600, Loss: 0.3587932586669922, Accuracy: 92.5%\n",
      "Epoch: 3, Step: 650, Loss: 0.5157994031906128, Accuracy: 92.47%\n",
      "Epoch: 3, Step: 700, Loss: 0.2115875631570816, Accuracy: 92.5%\n",
      "Epoch: 3, Step: 750, Loss: 0.3737974464893341, Accuracy: 92.48%\n",
      "Epoch: 3, Step: 800, Loss: 0.22272402048110962, Accuracy: 92.54%\n",
      "Epoch: 3, Step: 850, Loss: 0.33898353576660156, Accuracy: 92.62%\n",
      "Epoch: 3, Step: 900, Loss: 0.2183847278356552, Accuracy: 92.6%\n",
      "Epoch: 3, Step: 950, Loss: 0.4499428868293762, Accuracy: 92.55%\n",
      "Epoch: 3, Step: 1000, Loss: 0.2325446903705597, Accuracy: 92.53%\n",
      "Epoch: 3, Step: 1050, Loss: 0.2973219156265259, Accuracy: 92.54%\n",
      "Epoch: 3, Step: 1100, Loss: 0.3466407060623169, Accuracy: 92.56%\n",
      "Epoch: 3, Step: 1150, Loss: 0.21677301824092865, Accuracy: 92.48%\n",
      "Epoch: 4, Step: 0, Loss: 0.3884218633174896, Accuracy: 91.28%\n",
      "Epoch: 4, Step: 50, Loss: 0.42397454380989075, Accuracy: 91.78%\n",
      "Epoch: 4, Step: 100, Loss: 0.3308045268058777, Accuracy: 91.76%\n",
      "Epoch: 4, Step: 150, Loss: 0.43591463565826416, Accuracy: 91.87%\n",
      "Epoch: 4, Step: 200, Loss: 0.2207968831062317, Accuracy: 91.66%\n",
      "Epoch: 4, Step: 250, Loss: 0.41789790987968445, Accuracy: 91.78%\n",
      "Epoch: 4, Step: 300, Loss: 0.46803757548332214, Accuracy: 91.78%\n",
      "Epoch: 4, Step: 350, Loss: 0.32638123631477356, Accuracy: 91.82%\n",
      "Epoch: 4, Step: 400, Loss: 0.2670483887195587, Accuracy: 91.86%\n",
      "Epoch: 4, Step: 450, Loss: 0.3224220275878906, Accuracy: 91.83%\n",
      "Epoch: 4, Step: 500, Loss: 0.41858333349227905, Accuracy: 91.77%\n",
      "Epoch: 4, Step: 550, Loss: 0.32680603861808777, Accuracy: 91.82%\n",
      "Epoch: 4, Step: 600, Loss: 0.3358049690723419, Accuracy: 91.86%\n",
      "Epoch: 4, Step: 650, Loss: 0.48883548378944397, Accuracy: 91.99%\n",
      "Epoch: 4, Step: 700, Loss: 0.2917739748954773, Accuracy: 92.02%\n",
      "Epoch: 4, Step: 750, Loss: 0.24738870561122894, Accuracy: 92.0%\n",
      "Epoch: 4, Step: 800, Loss: 0.1828436702489853, Accuracy: 92.11%\n",
      "Epoch: 4, Step: 850, Loss: 0.31731581687927246, Accuracy: 92.06%\n",
      "Epoch: 4, Step: 900, Loss: 0.25178974866867065, Accuracy: 92.0%\n",
      "Epoch: 4, Step: 950, Loss: 0.2522376775741577, Accuracy: 92.04%\n",
      "Epoch: 4, Step: 1000, Loss: 0.29832085967063904, Accuracy: 92.02%\n",
      "Epoch: 4, Step: 1050, Loss: 0.3510795533657074, Accuracy: 92.1%\n",
      "Epoch: 4, Step: 1100, Loss: 0.4624330997467041, Accuracy: 92.01%\n",
      "Epoch: 4, Step: 1150, Loss: 0.2844058871269226, Accuracy: 92.1%\n",
      "Epoch: 5, Step: 0, Loss: 0.34041106700897217, Accuracy: 90.52%\n",
      "Epoch: 5, Step: 50, Loss: 0.5017946362495422, Accuracy: 90.98%\n",
      "Epoch: 5, Step: 100, Loss: 0.3865715265274048, Accuracy: 90.96%\n",
      "Epoch: 5, Step: 150, Loss: 0.3856615424156189, Accuracy: 90.98%\n",
      "Epoch: 5, Step: 200, Loss: 0.5814909934997559, Accuracy: 91.0%\n",
      "Epoch: 5, Step: 250, Loss: 0.3484534025192261, Accuracy: 91.06%\n",
      "Epoch: 5, Step: 300, Loss: 0.39731159806251526, Accuracy: 90.93%\n",
      "Epoch: 5, Step: 350, Loss: 0.6947617530822754, Accuracy: 91.11%\n",
      "Epoch: 5, Step: 400, Loss: 0.4992348849773407, Accuracy: 91.13%\n",
      "Epoch: 5, Step: 450, Loss: 0.2818603515625, Accuracy: 91.17%\n",
      "Epoch: 5, Step: 500, Loss: 0.437979519367218, Accuracy: 91.14%\n",
      "Epoch: 5, Step: 550, Loss: 0.3221326470375061, Accuracy: 91.23%\n",
      "Epoch: 5, Step: 600, Loss: 0.3856266140937805, Accuracy: 91.25%\n",
      "Epoch: 5, Step: 650, Loss: 0.37708717584609985, Accuracy: 91.23%\n",
      "Epoch: 5, Step: 700, Loss: 0.41771721839904785, Accuracy: 91.19%\n",
      "Epoch: 5, Step: 750, Loss: 0.33227160573005676, Accuracy: 91.11%\n",
      "Epoch: 5, Step: 800, Loss: 0.5944967269897461, Accuracy: 91.25%\n",
      "Epoch: 5, Step: 850, Loss: 0.33891382813453674, Accuracy: 91.28%\n",
      "Epoch: 5, Step: 900, Loss: 0.37513992190361023, Accuracy: 91.3%\n",
      "Epoch: 5, Step: 950, Loss: 0.574822723865509, Accuracy: 91.33%\n",
      "Epoch: 5, Step: 1000, Loss: 0.4898715615272522, Accuracy: 91.4%\n",
      "Epoch: 5, Step: 1050, Loss: 0.3530840277671814, Accuracy: 91.35%\n",
      "Epoch: 5, Step: 1100, Loss: 0.33943459391593933, Accuracy: 91.39%\n",
      "Epoch: 5, Step: 1150, Loss: 0.34427928924560547, Accuracy: 91.35%\n",
      "Epoch: 6, Step: 0, Loss: 0.31505611538887024, Accuracy: 89.04%\n",
      "Epoch: 6, Step: 50, Loss: 0.6460347771644592, Accuracy: 89.87%\n",
      "Epoch: 6, Step: 100, Loss: 0.7005337476730347, Accuracy: 89.91%\n",
      "Epoch: 6, Step: 150, Loss: 0.5925394296646118, Accuracy: 90.07%\n",
      "Epoch: 6, Step: 200, Loss: 0.5322741270065308, Accuracy: 90.12%\n",
      "Epoch: 6, Step: 250, Loss: 0.4679630398750305, Accuracy: 90.05%\n",
      "Epoch: 6, Step: 300, Loss: 0.46316853165626526, Accuracy: 90.16%\n",
      "Epoch: 6, Step: 350, Loss: 0.47555011510849, Accuracy: 90.13%\n",
      "Epoch: 6, Step: 400, Loss: 0.4657285809516907, Accuracy: 90.07%\n",
      "Epoch: 6, Step: 450, Loss: 0.46684741973876953, Accuracy: 90.1%\n",
      "Epoch: 6, Step: 500, Loss: 0.4772215783596039, Accuracy: 90.07%\n",
      "Epoch: 6, Step: 550, Loss: 0.5346285104751587, Accuracy: 90.12%\n",
      "Epoch: 6, Step: 600, Loss: 0.42965081334114075, Accuracy: 90.21%\n",
      "Epoch: 6, Step: 650, Loss: 0.5548136234283447, Accuracy: 90.2%\n",
      "Epoch: 6, Step: 700, Loss: 0.3816833794116974, Accuracy: 90.19%\n",
      "Epoch: 6, Step: 750, Loss: 0.5054651498794556, Accuracy: 90.31%\n",
      "Epoch: 6, Step: 800, Loss: 0.4601239264011383, Accuracy: 90.31%\n",
      "Epoch: 6, Step: 850, Loss: 0.6343863606452942, Accuracy: 90.31%\n",
      "Epoch: 6, Step: 900, Loss: 0.2442188858985901, Accuracy: 90.37%\n",
      "Epoch: 6, Step: 950, Loss: 0.4333128333091736, Accuracy: 90.32%\n",
      "Epoch: 6, Step: 1000, Loss: 0.4788167476654053, Accuracy: 90.36%\n",
      "Epoch: 6, Step: 1050, Loss: 0.3221801519393921, Accuracy: 90.35%\n",
      "Epoch: 6, Step: 1100, Loss: 0.4616929590702057, Accuracy: 90.34%\n",
      "Epoch: 6, Step: 1150, Loss: 0.4260232448577881, Accuracy: 90.39%\n",
      "Epoch: 7, Step: 0, Loss: 0.49802935123443604, Accuracy: 86.13%\n",
      "Epoch: 7, Step: 50, Loss: 0.7303926348686218, Accuracy: 87.31%\n",
      "Epoch: 7, Step: 100, Loss: 0.6322535872459412, Accuracy: 87.99%\n",
      "Epoch: 7, Step: 150, Loss: 0.5314939618110657, Accuracy: 88.27%\n",
      "Epoch: 7, Step: 200, Loss: 0.4424760937690735, Accuracy: 88.5%\n",
      "Epoch: 7, Step: 250, Loss: 0.47390735149383545, Accuracy: 88.51%\n",
      "Epoch: 7, Step: 300, Loss: 0.5877199769020081, Accuracy: 88.57%\n",
      "Epoch: 7, Step: 350, Loss: 0.6686925292015076, Accuracy: 88.59%\n",
      "Epoch: 7, Step: 400, Loss: 0.4816072881221771, Accuracy: 88.59%\n",
      "Epoch: 7, Step: 450, Loss: 0.6088556051254272, Accuracy: 88.57%\n",
      "Epoch: 7, Step: 500, Loss: 0.5133657455444336, Accuracy: 88.65%\n",
      "Epoch: 7, Step: 550, Loss: 0.6061494946479797, Accuracy: 88.62%\n",
      "Epoch: 7, Step: 600, Loss: 0.4611092507839203, Accuracy: 88.66%\n",
      "Epoch: 7, Step: 650, Loss: 0.4381924569606781, Accuracy: 88.72%\n",
      "Epoch: 7, Step: 700, Loss: 0.44467711448669434, Accuracy: 88.79%\n",
      "Epoch: 7, Step: 750, Loss: 0.48468077182769775, Accuracy: 88.82%\n",
      "Epoch: 7, Step: 800, Loss: 0.5140219330787659, Accuracy: 88.81%\n",
      "Epoch: 7, Step: 850, Loss: 0.486390084028244, Accuracy: 88.82%\n",
      "Epoch: 7, Step: 900, Loss: 0.532517671585083, Accuracy: 88.83%\n",
      "Epoch: 7, Step: 950, Loss: 0.48921000957489014, Accuracy: 88.93%\n",
      "Epoch: 7, Step: 1000, Loss: 0.5776922702789307, Accuracy: 88.84%\n",
      "Epoch: 7, Step: 1050, Loss: 0.4695260226726532, Accuracy: 88.89%\n",
      "Epoch: 7, Step: 1100, Loss: 0.4360889196395874, Accuracy: 88.86%\n",
      "Epoch: 7, Step: 1150, Loss: 0.49605533480644226, Accuracy: 88.85%\n",
      "Epoch: 8, Step: 0, Loss: 0.6181567907333374, Accuracy: 84.89%\n",
      "Epoch: 8, Step: 50, Loss: 0.7473436594009399, Accuracy: 85.23%\n",
      "Epoch: 8, Step: 100, Loss: 0.7829402685165405, Accuracy: 85.35%\n",
      "Epoch: 8, Step: 150, Loss: 0.7908051013946533, Accuracy: 85.51%\n",
      "Epoch: 8, Step: 200, Loss: 0.8061378598213196, Accuracy: 85.54%\n",
      "Epoch: 8, Step: 250, Loss: 0.785102903842926, Accuracy: 85.67%\n",
      "Epoch: 8, Step: 300, Loss: 0.6714630126953125, Accuracy: 85.73%\n",
      "Epoch: 8, Step: 350, Loss: 0.6816689968109131, Accuracy: 85.72%\n",
      "Epoch: 8, Step: 400, Loss: 0.3867732882499695, Accuracy: 85.72%\n",
      "Epoch: 8, Step: 450, Loss: 0.7309884428977966, Accuracy: 85.71%\n",
      "Epoch: 8, Step: 500, Loss: 0.6670750975608826, Accuracy: 85.77%\n",
      "Epoch: 8, Step: 550, Loss: 0.6811389923095703, Accuracy: 85.8%\n",
      "Epoch: 8, Step: 600, Loss: 0.5888237357139587, Accuracy: 85.79%\n",
      "Epoch: 8, Step: 650, Loss: 0.6684473156929016, Accuracy: 85.85%\n",
      "Epoch: 8, Step: 700, Loss: 0.5566012859344482, Accuracy: 85.86%\n",
      "Epoch: 8, Step: 750, Loss: 0.6038612723350525, Accuracy: 85.84%\n",
      "Epoch: 8, Step: 800, Loss: 0.49638134241104126, Accuracy: 85.88%\n",
      "Epoch: 8, Step: 850, Loss: 0.5997098684310913, Accuracy: 85.97%\n",
      "Epoch: 8, Step: 900, Loss: 0.5581543445587158, Accuracy: 85.95%\n",
      "Epoch: 8, Step: 950, Loss: 0.7145189642906189, Accuracy: 85.91%\n",
      "Epoch: 8, Step: 1000, Loss: 0.5251068472862244, Accuracy: 85.87%\n",
      "Epoch: 8, Step: 1050, Loss: 0.4830101728439331, Accuracy: 85.9%\n",
      "Epoch: 8, Step: 1100, Loss: 0.6098264455795288, Accuracy: 85.97%\n",
      "Epoch: 8, Step: 1150, Loss: 0.5882217288017273, Accuracy: 85.91%\n",
      "Epoch: 9, Step: 0, Loss: 0.6142472624778748, Accuracy: 82.22%\n",
      "Epoch: 9, Step: 50, Loss: 0.8102648854255676, Accuracy: 82.6%\n",
      "Epoch: 9, Step: 100, Loss: 0.8018410205841064, Accuracy: 82.91%\n",
      "Epoch: 9, Step: 150, Loss: 0.8019728660583496, Accuracy: 83.13%\n",
      "Epoch: 9, Step: 200, Loss: 0.7368123531341553, Accuracy: 83.33%\n",
      "Epoch: 9, Step: 250, Loss: 0.7827438116073608, Accuracy: 83.42%\n",
      "Epoch: 9, Step: 300, Loss: 0.7658268809318542, Accuracy: 83.48%\n",
      "Epoch: 9, Step: 350, Loss: 0.7398829460144043, Accuracy: 83.57%\n",
      "Epoch: 9, Step: 400, Loss: 0.6622118353843689, Accuracy: 83.6%\n",
      "Epoch: 9, Step: 450, Loss: 0.7663429975509644, Accuracy: 83.66%\n",
      "Epoch: 9, Step: 500, Loss: 0.7523587942123413, Accuracy: 83.77%\n",
      "Epoch: 9, Step: 550, Loss: 0.7958832383155823, Accuracy: 83.79%\n",
      "Epoch: 9, Step: 600, Loss: 0.6006925702095032, Accuracy: 83.73%\n",
      "Epoch: 9, Step: 650, Loss: 0.7191467881202698, Accuracy: 83.72%\n",
      "Epoch: 9, Step: 700, Loss: 0.6821465492248535, Accuracy: 83.83%\n",
      "Epoch: 9, Step: 750, Loss: 0.5841840505599976, Accuracy: 83.78%\n",
      "Epoch: 9, Step: 800, Loss: 0.6753990054130554, Accuracy: 83.79%\n",
      "Epoch: 9, Step: 850, Loss: 0.6360914707183838, Accuracy: 83.85%\n",
      "Epoch: 9, Step: 900, Loss: 0.7003185153007507, Accuracy: 83.83%\n",
      "Epoch: 9, Step: 950, Loss: 0.6443332433700562, Accuracy: 83.86%\n",
      "Epoch: 9, Step: 1000, Loss: 0.7233798503875732, Accuracy: 83.94%\n",
      "Epoch: 9, Step: 1050, Loss: 0.7094301581382751, Accuracy: 84.01%\n",
      "Epoch: 9, Step: 1100, Loss: 0.8245548009872437, Accuracy: 84.03%\n",
      "Epoch: 9, Step: 1150, Loss: 0.8868556022644043, Accuracy: 84.04%\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 3               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001             \n",
    "TSNE = False\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "\n",
    "# create model instance\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='gupta',p=60)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                  \n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinningup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
